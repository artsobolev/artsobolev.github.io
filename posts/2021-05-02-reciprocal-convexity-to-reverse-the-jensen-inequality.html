<!DOCTYPE html>
<html lang="en">
<head>
  <title>Reciprocal Convexity to reverse the Jensen Inequality – B.log</title>
  <meta charset="utf-8" />

  <meta property="twitter:card" content="summary" />
  <meta name="twitter:site" content="@art_sobolev" />
  <meta property="og:title" content="Reciprocal Convexity to reverse the Jensen Inequality – B.log" />
  <meta property="og:description" content="Jensen's inequality is a powerful tool often used in mathematical derivations and analyses. It states that for a convex function $f(x)$ and an arbitrary random variable $X$ we have the following upper bound: $$ f\left(\E X\right) \le \E..." />
  <meta property="og:image" content="http://artem.sobolev.name/files/rev-jens.jpg" />
  <link rel="shortcut icon" href="/favicon.ico"/>

  <link rel="stylesheet" type="text/css" href="/theme/css/default.css" />
  <link rel="stylesheet" type="text/css" href="/theme/css/syntax.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:,b" />
  <script type="text/javascript">
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        macros: {
	  E: '\\mathop{\\mathbb{E}}'
	}
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <header>
      <hgroup>
        <h1><a href="/">B.log</a></h1>
        <h2>Random notes mostly on Machine Learning</h2>
      </hgroup>
    </header>
    <nav>
        <menu>
          <a href="/">Home</a>
          <a href="/pages/about.html">About me</a>
          <a href="http://feeds.feedburner.com/barmaley-exe-blog-feed">RSS feed</a>
        </menu>
    </nav>
    <section>
<article>
<header>
	<h1>Reciprocal Convexity to reverse the Jensen Inequality</h1>
	<time>May 2, 2021</time>
</header>

<section class="post-body">
    <p><a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen's inequality</a> is a powerful tool often used in mathematical derivations and analyses. It states that for a convex function $f(x)$ and an arbitrary random variable $X$ we have the following <em>upper</em> bound:
$$
f\left(\E X\right)
\le
\E f\left(X\right)
$$</p>
<p>However, oftentimes we want the inequality to work in the other direction, to give a <em>lower</em> bound. In this post I'll outline one possible approach to this.</p>
<!--more-->

<h2>The Trick</h2>
<p>The basic idea is very simple: let's turn our convex function into a concave function. First, define</p>
<p>$$
\hat{f}(x) = f\left(\tfrac{1}{x}\right)
$$</p>
<p>As <a href="https://core.ac.uk/download/pdf/82634388.pdf">defined by Merkle</a>, a function $h(x)$ is called <strong>reciprocally convex</strong> if $h(x)$ is concave and $\hat{h}(x) = h(1/x)$ is convex. For the sake of this discussion we'll assume $f(x)$ is <strong>reciprocally concave</strong>, that is, of course, $-f(x)$ is reciprocally convex.</p>
<p>Next, we'll need an unbiased estimator $Y$ of the reciprocal of the mean $\E X$, that is, $Y$ should satisfy the following:</p>
<p>$$
\E Y = \frac{1}{\E X}
$$</p>
<p>Now, the rest is simple algebra and the standard Jensen's inequality (remember $\hat{f}$ is concave by definition):
$$
f\left(\E X\right)
= \hat{f}\left(\frac{1}{\E X}\right)
= \hat{f}\left(\E Y\right)
\ge \E \hat{f}\left(Y\right)
= \E f\left(\frac{1}{Y}\right)
\tag{1}
$$</p>
<h3>Example</h3>
<p>This trick is actually the reason why we can have both <a href="/posts/2019-05-10-importance-weighted-hierarchical-variational-inference.html">upper</a> and lower bounds on the log marginal likelihood in latent variable models. Indeed, consider the following example:</p>
<p>$$
f(x) := -\log(x),
\quad X := p(x \mid Z),
\quad Z \sim p(z)
$$</p>
<p>This is the standard Variational Inference setup. Putting it all together, we'd like to give bounds on</p>
<p>$$
-\log \left( \E_{Z \sim p(z)} p(x|Z) \right)
= -\log p(x)
$$</p>
<p>Normally, in VI we use the standard Jensen's Inequality to obtain an upper bound on this negative log-likelihood, and all is good. However, sometimes we need lower bounds on the same quantity. This is where the framework above comes to the rescue.</p>
<p>First, it's easy to see that we're very lucky – $f(x)$ is indeed reciprocally concave: $-\log(x)$ is convex, and $-\log\tfrac{1}{x} = \log(x)$ is concave.</p>
<p>Next, we need an unbiased estimator $Y$ of the inverse mean of $X$, that is, an unbiased estimator of $1/p(x)$. Such estimator can be given this way:</p>
<p>$$
\frac{1}{p(x)}
= \int \frac{q(z)}{p(x)} dz
= \int \frac{q(z) p(z|x)}{p(x) p(z | x)} dz
= \E_{p(z|x)} \frac{q(z)}{p(x, z)}
$$</p>
<p>Where $q(z)$ is an arbitrary distribution. Thus, the estimator is $Y$ generated by r.v. $Z$:
$$
Y := \frac{q(Z)}{p(x, Z)},
\quad Z \sim p(z|x)
$$</p>
<p>Now, putting these into (1) we obtain:
$$
-\log p(x)
\ge -\E_{p(z|x)} \log \frac{p(x, z)}{q(z)}
$$
Or, equivalently,
$$
\log p(x)
\le \E_{p(z|x)} \log \frac{p(x, z)}{q(z)}
$$
By the way, for comparison, here's the classical lower bound obtained through the standard Jensen's Inequality. Curiously, the only difference is where the random variables $z$ are coming from:
$$
\log p(x)
\ge \E_{q(z)} \log \frac{p(x, z)}{q(z)}
$$</p>
<h3>Generalization</h3>
<p>Why limit ourselves to a particular $\hat{f} = f \circ (1/x)$? One can consider other invertible functions $g(x)$ instead of the $1/x$. Here's the recipe:</p>
<ul>
<li>Define $f^{[g]}(x) = f(g(x))$</li>
<li>First, we need $f^{[g]}(x)$ to be concave</li>
<li>Second, we need an unbiased estimator $Y$ of $g^{-1}(\E X)$</li>
</ul>
<p>This leads to a generalization of (1):
$$
f\left(\E X\right)
= f^{[g]}\left( g^{-1}(\E X) \right)
= f^{[g]}\left( \E Y \right)
\ge \E f^{[g]}\left( Y \right)
= \E f\left( g(Y) \right)
$$</p>
<h2>Conclusion</h2>
<p>This trick is simple, and perhaps obvious even without any fancy words such as reciprocal convexity. Moreover, it has its limitations: you either need to get lucky with $f(x)$ being reciprocally concave, or need to find an invertible $g(x)$ such that $f \circ g$ is concave. But even that's not enough, as you also need to construct an unbiased estimator $Y$, and if you fancy practical applications, efficiency of the resulting bound will heavily depend on the quality of this
estimator.</p>
<p>Nevertheless, I believe this is an interesting idea and it might prove itself useful in various analyses and derivations.</p>
</section>

<div class="tags-pane">Tagged as <a href="/tags/math.html">math</a></div>
</article>

<section class="post-comments">
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'barmaley-exe'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>
    </section>
    <footer>
        Generated with Pelican 
    </footer>

<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-38530232-1']);
_gaq.push(['_trackPageview']);
(function() {
 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
 ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>
</body>
</html>